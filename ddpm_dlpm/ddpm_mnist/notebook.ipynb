{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nfrom pathlib import Path\n\nproject_root = Path.cwd().parent.parent\nos.chdir(project_root)\n\nif str(project_root) not in sys.path:\n    sys.path.insert(0, str(project_root))\n\nimport torch\nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom ddpm_dlpm.custom_data import CustomMnistDataset\nfrom ddpm_dlpm.ddpm_mnist.config import CONFIG\nfrom ddpm_dlpm.unet import Unet\nfrom ddpm_dlpm.process import DDPM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Loading MNIST dataset...\")\ntrain_csv = CONFIG.data_dir / \"train.csv\"\nmnist_ds = CustomMnistDataset(str(train_csv))\nmnist_dl = DataLoader(mnist_ds, batch_size=CONFIG.batch_size, shuffle=False)\n\nprint(f\"Dataset size: {len(mnist_ds)} images\")\nprint(f\"Number of batches: {len(mnist_dl)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7csipkk84",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*50)\nprint(\"Sample Images from Dataset\")\nprint(\"=\"*50 + \"\\n\")\n\n# Display 16 sample images in a 4x4 grid\nfig, axes = plt.subplots(4, 4, figsize=(8, 8))\naxes = axes.flatten()\n\nfor i in range(16):\n    img = mnist_ds[i]\n    # Convert from [-1, 1] to [0, 255] for display\n    img_display = ((img.squeeze() + 1) / 2 * 255).numpy().astype(np.uint8)\n    \n    axes[i].imshow(img_display, cmap=CONFIG.cmap, vmin=0, vmax=255)\n    axes[i].axis('off')\n    axes[i].set_title(f\"Sample {i+1}\", fontsize=10)\n\nplt.suptitle(\"MNIST Dataset Samples\", fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"Images are preprocessed to range [-1, 1], displayed as [0, 255]\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c22209",
   "metadata": {},
   "outputs": [],
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {device}\\n\")\n\nmodel = Unet(im_channels=CONFIG.im_channels).to(device)\nprint(\"Created untrained UNet with random weights\")\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total parameters: {num_params:,}\\n\")\n\nfp = DDPM().to(device)\n\ncriterion = torch.nn.MSELoss()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c217fc29",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*50)\nprint(\"Forward Process Visualization\")\nprint(\"=\"*50 + \"\\n\")\n\nsample_img = mnist_ds[0].unsqueeze(0).to(device)\n\n# Timesteps to visualize: clean image (0), then 1, 2, 5, 10, 25, 100, 500, 999\ntimesteps = [0, 1, 2, 5, 10, 25, 100, 500, 999]\n\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor i, t_val in enumerate(timesteps):\n    if t_val == 0:\n        # Show clean image\n        img_display = ((sample_img[0, 0].cpu() + 1) / 2 * 255).numpy().astype(np.uint8)\n        axes[i].imshow(img_display, cmap=CONFIG.cmap, vmin=0, vmax=255)\n        axes[i].set_title(f\"Clean Image (t=0)\", fontsize=12, fontweight='bold')\n    else:\n        # Apply forward diffusion\n        noise = torch.randn_like(sample_img)\n        t_tensor = torch.tensor([t_val], device=device)\n        noisy_img = fp.forward(sample_img, noise, t_tensor)\n        \n        # Convert to [0, 255] for display\n        img_display = ((noisy_img[0, 0].cpu() + 1) / 2 * 255).numpy().astype(np.uint8)\n        axes[i].imshow(img_display, cmap=CONFIG.cmap, vmin=0, vmax=255)\n        axes[i].set_title(f\"After t={t_val} steps\", fontsize=12)\n    \n    axes[i].axis(\"off\")\n\nplt.suptitle(\"Forward Diffusion Process: Progressive Noise Addition\", fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(f\"Visualization shows how noise is gradually added over {CONFIG.num_timesteps} timesteps\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean and std...\\n\")\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for batch in tqdm(mnist_dl, desc=\"Loading batches\"):\n",
    "    all_data.append(batch)\n",
    "\n",
    "all_data = torch.cat(all_data, dim=0)\n",
    "print(f\"Total data shape: {all_data.shape}\\n\")\n",
    "\n",
    "mean = torch.mean(all_data).item()\n",
    "std = torch.std(all_data).item()\n",
    "\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"MNIST Statistics (after standardization to [-1, 1]):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Mean: {mean:.6f}\")\n",
    "print(f\"Std:  {std:.6f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "print(f\"\\nData min value: {all_data.min().item():.4f}\")\n",
    "print(f\"Data max value: {all_data.max().item():.4f}\")\n",
    "\n",
    "del all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": "imgs = next(iter(mnist_dl)).to(device)\nprint(f\"Batch shape: {imgs.shape}\")\nprint(f\"Batch size: {imgs.shape[0]}\\n\")\n\nnoise = torch.randn_like(imgs).to(device)\nt = torch.randint(0, CONFIG.num_timesteps, (imgs.shape[0],)).to(device)\nnoisy_imgs = fp.forward(imgs, noise, t)\n\nmodel.eval()\nwith torch.no_grad():\n    noise_pred = model(noisy_imgs, t)\n    loss = criterion(noise_pred, noise)\n\nprint(f\"{'='*50}\")\nprint(f\"Initial Loss (Untrained UNet):\")\nprint(f\"{'='*50}\")\nprint(f\"MSE Loss: {loss.item():.6f}\")\nprint(f\"{'='*50}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}